{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"Seq2seq Генерация кода по вопросам со StackOverflo.ipynb","provenance":[{"file_id":"https://github.com/Samsung-IT-Academy/stepik-dl-nlp/blob/master/task8_generate_stackoverflow_code.ipynb","timestamp":1587804316302}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"C1KEPFIogu5V","colab_type":"text"},"source":["# Генерация кода по вопросам со StackOverflow\n"]},{"cell_type":"code","metadata":{"id":"Gp0VVYVLgu5X","colab_type":"code","outputId":"cde1768b-555c-4e0e-e75b-91d8150820c0","executionInfo":{"status":"ok","timestamp":1587827514982,"user_tz":-240,"elapsed":1976,"user":{"displayName":"Alexcei64rus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4SypAswQozU3-DGFu0VQyxwB_TSZLCZKDR1Z6Cg=s64","userId":"06079512506264468138"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Если Вы запускаете ноутбук на colab или kaggle,\n","# выполните следующие строчки, чтобы подгрузить библиотеку dlnlputils:\n","\n","!git clone https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git && pip install -r stepik-dl-nlp/requirements.txt\n","import sys; sys.path.append('./stepik-dl-nlp')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["fatal: destination path 'stepik-dl-nlp' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"76HsmSQF7E5c","colab_type":"code","outputId":"9d280a5a-5e69-47cd-90a7-5bfae7464093","executionInfo":{"status":"ok","timestamp":1587827519756,"user_tz":-240,"elapsed":2160,"user":{"displayName":"Alexcei64rus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4SypAswQozU3-DGFu0VQyxwB_TSZLCZKDR1Z6Cg=s64","userId":"06079512506264468138"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["!nvidia-smi"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Sat Apr 25 15:11:55 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   71C    P8    32W / 149W |      0MiB / 11441MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_h8UvUo85Ctp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"93095cb1-b4ca-4acb-cf72-782f83348c64","executionInfo":{"status":"ok","timestamp":1587827526893,"user_tz":-240,"elapsed":4114,"user":{"displayName":"Alexcei64rus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4SypAswQozU3-DGFu0VQyxwB_TSZLCZKDR1Z6Cg=s64","userId":"06079512506264468138"}}},"source":["!pip install -r stepik-dl-nlp/requirements.txt"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 1)) (0.22.2.post1)\n","Requirement already satisfied: spacy-udpipe in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 2)) (0.2.1)\n","Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 3)) (0.8)\n","Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 4)) (1.4.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 5)) (3.2.1)\n","Requirement already satisfied: ipymarkup in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 6)) (0.7.0)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 7)) (4.2.6)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 8)) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 9)) (1.0.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 10)) (4.38.0)\n","Requirement already satisfied: youtokentome in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 11)) (1.0.6)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 12)) (0.10.0)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 13)) (4.10.1)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 14)) (5.5.0)\n","Requirement already satisfied: pyconll in /usr/local/lib/python3.6/dist-packages (from -r stepik-dl-nlp/requirements.txt (line 15)) (2.2.1)\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r stepik-dl-nlp/requirements.txt (line 1)) (1.18.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r stepik-dl-nlp/requirements.txt (line 1)) (0.14.1)\n","Requirement already satisfied: spacy>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (2.2.4)\n","Requirement already satisfied: ufal.udpipe>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (1.2.0.3)\n","Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from pymorphy2->-r stepik-dl-nlp/requirements.txt (line 3)) (2.4.393442.3710985)\n","Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2->-r stepik-dl-nlp/requirements.txt (line 3)) (0.6.2)\n","Requirement already satisfied: dawg-python>=0.7 in /usr/local/lib/python3.6/dist-packages (from pymorphy2->-r stepik-dl-nlp/requirements.txt (line 3)) (0.7.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r stepik-dl-nlp/requirements.txt (line 5)) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r stepik-dl-nlp/requirements.txt (line 5)) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r stepik-dl-nlp/requirements.txt (line 5)) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r stepik-dl-nlp/requirements.txt (line 5)) (1.2.0)\n","Requirement already satisfied: intervaltree>=3 in /usr/local/lib/python3.6/dist-packages (from ipymarkup->-r stepik-dl-nlp/requirements.txt (line 6)) (3.0.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r stepik-dl-nlp/requirements.txt (line 9)) (2018.9)\n","Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from youtokentome->-r stepik-dl-nlp/requirements.txt (line 11)) (7.1.1)\n","Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (4.5.3)\n","Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (4.3.3)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (5.3.4)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (4.8.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (46.1.3)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (4.4.2)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (0.8.1)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (2.1.3)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (0.7.5)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (1.0.18)\n","Requirement already satisfied: requests>=2.21 in /usr/local/lib/python3.6/dist-packages (from pyconll->-r stepik-dl-nlp/requirements.txt (line 15)) (2.21.0)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (1.0.0)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (1.1.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (0.6.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (1.0.2)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (2.0.3)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (3.0.2)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (0.4.1)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (1.0.2)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (7.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->-r stepik-dl-nlp/requirements.txt (line 5)) (1.12.0)\n","Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.6/dist-packages (from intervaltree>=3->ipymarkup->-r stepik-dl-nlp/requirements.txt (line 6)) (2.1.0)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (0.2.0)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (19.0.0)\n","Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->-r stepik-dl-nlp/requirements.txt (line 13)) (4.6.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (0.6.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->-r stepik-dl-nlp/requirements.txt (line 14)) (0.1.9)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.21->pyconll->-r stepik-dl-nlp/requirements.txt (line 15)) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.21->pyconll->-r stepik-dl-nlp/requirements.txt (line 15)) (2020.4.5.1)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.21->pyconll->-r stepik-dl-nlp/requirements.txt (line 15)) (2.8)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.21->pyconll->-r stepik-dl-nlp/requirements.txt (line 15)) (1.24.3)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (1.6.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.1.0->spacy-udpipe->-r stepik-dl-nlp/requirements.txt (line 2)) (3.1.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kf-oGZ0f7Ixy","colab_type":"code","colab":{}},"source":["import gc # чистим память если что-то пошло не так\n","model = None\n","gc.collect()\n","torch.cuda.empty_cache()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hjgzxu3Bgu5d","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","from torchtext.datasets import TranslationDataset, Multi30k\n","from torchtext.data import Field, BucketIterator\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","\n","import spacy\n","\n","import random\n","import math\n","import time"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xC9D-uu3gu5h","colab_type":"code","colab":{}},"source":["SEED = 1234\n","\n","random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"J4dISgz6kw-Z","colab_type":"code","outputId":"9c08003c-34db-4e2c-90d4-7c8196b7e4d3","executionInfo":{"status":"ok","timestamp":1587820014058,"user_tz":-240,"elapsed":98122,"user":{"displayName":"Alexcei64rus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4SypAswQozU3-DGFu0VQyxwB_TSZLCZKDR1Z6Cg=s64","userId":"06079512506264468138"}},"colab":{"base_uri":"https://localhost:8080/","height":142}},"source":["import pandas as pd\n","\n","df = pd.read_csv('./stepik-dl-nlp/datasets/stackoverflow_code_generation/conala/conala-train.csv')\n","df.head(3)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>intent</th>\n","      <th>snippet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>How to convert a list of multiple integers int...</td>\n","      <td>sum(d * 10 ** i for i, d in enumerate(x[::-1]))</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>How to convert a list of multiple integers int...</td>\n","      <td>r = int(''.join(map(str, x)))</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>how to convert a datetime string back to datet...</td>\n","      <td>datetime.strptime('2010-11-13 10:33:54.227806'...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              intent                                            snippet\n","0  How to convert a list of multiple integers int...    sum(d * 10 ** i for i, d in enumerate(x[::-1]))\n","1  How to convert a list of multiple integers int...                      r = int(''.join(map(str, x)))\n","2  how to convert a datetime string back to datet...  datetime.strptime('2010-11-13 10:33:54.227806'..."]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"9B3ysB9Ogu5n","colab_type":"code","colab":{}},"source":["import re\n","\n","def tokenize_question(text):\n","    \"\"\"\n","    Tokenizes question from a string into a list of strings (tokens) and reverses it\n","    \"\"\"\n","    return list(filter(lambda x: len(x) < 16, re.findall(r\"[\\w']+\", text)[::-1]))\n","\n","def tokenize_snippet(text):\n","    \"\"\"\n","    Tokenizes code snippet into a list of operands\n","    \"\"\"\n","    return list(filter(lambda x: len(x) < 10, re.findall(r\"[\\w']+|[.,!?;:@~(){}\\[\\]+-/=\\\\\\'\\\"\\`]\", text)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LRQIL5zggu5r","colab_type":"code","colab":{}},"source":["import torch\n","from torchtext import data, datasets\n","\n","SRC = data.Field(\n","    tokenize = tokenize_question, \n","    init_token = '<sos>', \n","    eos_token = '<eos>', \n","    lower = True,\n","    include_lengths = True\n",")\n","\n","TRG = data.Field(\n","    tokenize = tokenize_snippet, \n","    init_token = '<sos>', \n","    eos_token = '<eos>', \n","    lower = True\n",")\n","\n","fields = {\n","    'intent': ('src', SRC),\n","    'snippet': ('trg', TRG)\n","}\n","\n","# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n","train_data, valid_data, test_data = data.TabularDataset.splits(\n","                            path = './stepik-dl-nlp/datasets/stackoverflow_code_generation/conala/',\n","                            train = 'conala-train.csv',\n","                            validation = 'conala-valid.csv',\n","                            test = 'conala-test.csv',\n","                            format = 'csv',\n","                            fields = fields\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GhEji9m0gu5w","colab_type":"code","outputId":"1a011f37-3360-4784-900d-73c20a2ab24f","executionInfo":{"status":"ok","timestamp":1587820014062,"user_tz":-240,"elapsed":98064,"user":{"displayName":"Alexcei64rus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4SypAswQozU3-DGFu0VQyxwB_TSZLCZKDR1Z6Cg=s64","userId":"06079512506264468138"}},"colab":{"base_uri":"https://localhost:8080/","height":105}},"source":["SRC.build_vocab([train_data.src], max_size=25000, min_freq=3)\n","print(SRC.vocab.freqs.most_common(20))\n","\n","\n","TRG.build_vocab([train_data.trg], min_freq=5)\n","print(TRG.vocab.freqs.most_common(20))\n","\n","print(f\"Уникальные токены в словаре интентов: {len(SRC.vocab)}\")\n","print(f\"Уникальные токены в словаре сниппетов: {len(TRG.vocab)}\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[('a', 1285), ('in', 949), ('python', 922), ('to', 851), ('how', 633), ('of', 602), ('list', 558), ('string', 397), ('the', 328), ('from', 275), ('with', 228), ('pandas', 192), ('i', 191), ('dictionary', 162), ('get', 151), ('convert', 134), ('values', 131), ('do', 125), ('dataframe', 111), ('into', 110)]\n","[(')', 3480), ('(', 3475), ('.', 2595), (',', 1899), ('[', 1122), (']', 1121), ('=', 927), (\"'\", 885), ('\\\\', 697), (':', 587), ('in', 504), ('x', 498), ('\"', 496), ('for', 450), ('1', 377), ('-', 279), ('a', 265), ('0', 259), ('/', 257), ('df', 234)]\n","Уникальные токены в словаре интентов: 612\n","Уникальные токены в словаре сниппетов: 395\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"L9IQSkTHgu51","colab_type":"code","outputId":"b2dead94-d7b9-4cf9-d824-83236fdd4c14","executionInfo":{"status":"ok","timestamp":1587820014063,"user_tz":-240,"elapsed":98042,"user":{"displayName":"Alexcei64rus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4SypAswQozU3-DGFu0VQyxwB_TSZLCZKDR1Z6Cg=s64","userId":"06079512506264468138"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["print(f\"Размер обучающей выборки: {len(train_data.examples)}\")\n","print(f\"Размер валидационной выборки: {len(valid_data.examples)}\")\n","print(f\"Размер тестовой выборки: {len(test_data.examples)}\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Размер обучающей выборки: 2000\n","Размер валидационной выборки: 379\n","Размер тестовой выборки: 500\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SSVwf72xgu57","colab_type":"code","colab":{}},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","torch.cuda.set_device(0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DkGGlZksgu5_","colab_type":"code","outputId":"a37403f8-bb5b-4fb8-9e65-89ccb8d6de95","executionInfo":{"status":"ok","timestamp":1587827641024,"user_tz":-240,"elapsed":599,"user":{"displayName":"Alexcei64rus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4SypAswQozU3-DGFu0VQyxwB_TSZLCZKDR1Z6Cg=s64","userId":"06079512506264468138"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["device"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"SqecoqRhgu6D","colab_type":"code","colab":{}},"source":["BATCH_SIZE = 8\n","\n","train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n","    (train_data, valid_data, test_data), \n","     batch_size = BATCH_SIZE,\n","     sort_within_batch = True,\n","     sort_key = lambda x : len(x.src),\n","     device = device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"enRKk_2Mgu6K","colab_type":"code","colab":{}},"source":["class Encoder(nn.Module):\n","    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n","        super().__init__()\n","        \n","        self.input_dim = input_dim\n","        self.emb_dim = emb_dim\n","        self.enc_hid_dim = enc_hid_dim\n","        self.dec_hid_dim = dec_hid_dim\n","        self.dropout = dropout\n","        \n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","        \n","        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n","        \n","        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, src, \n","                ):\n","        \n","        #src = [src sent len, batch size]\n","        #src_len = [src sent len]\n","        \n","        embedded = self.dropout(self.embedding(src))\n","        \n","        #embedded = [src sent len, batch size, emb dim]\n","        \n","        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len)\n","        \n","        packed_outputs, hidden = self.rnn(packed_embedded)\n","                     \n","        #packed_outputs is a packed sequence containing all hidden states\n","        #hidden is now from the final non-padded element in the batch\n","            \n","        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs) \n","            \n","        #outputs is now a non-packed sequence, all hidden states obtained\n","        #  when the input is a pad token are all zeros\n","            \n","        #outputs = [sent len, batch size, hid dim * num directions]\n","        #hidden = [n layers * num directions, batch size, hid dim]\n","        \n","        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n","        #outputs are always from the last layer\n","        \n","        #hidden [-2, :, : ] is the last of the forwards RNN \n","        #hidden [-1, :, : ] is the last of the backwards RNN\n","        \n","        #initial decoder hidden is final hidden state of the forwards and backwards \n","        #  encoder RNNs fed through a linear layer\n","        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n","        \n","        #outputs = [sent len, batch size, enc hid dim * 2]\n","        #hidden = [batch size, dec hid dim]\n","        \n","        return outputs, hidden"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IpgofzPfgu6Q","colab_type":"code","colab":{}},"source":["class Attention(nn.Module):\n","    def __init__(self, enc_hid_dim, dec_hid_dim):\n","        super().__init__()\n","        \n","        self.enc_hid_dim = enc_hid_dim\n","        self.dec_hid_dim = dec_hid_dim\n","        \n","        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n","        self.v = nn.Parameter(torch.rand(dec_hid_dim))\n","        \n","    def forward(self, hidden, encoder_outputs, mask):\n","        \n","        #hidden = [batch size, dec hid dim]\n","        #encoder_outputs = [src sent len, batch size, enc hid dim * 2]\n","        #mask = [batch size, src sent len]\n","        \n","        batch_size = encoder_outputs.shape[1]\n","        src_len = encoder_outputs.shape[0]\n","        \n","        #repeat encoder hidden state src_len times\n","        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n","        \n","        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n","        \n","        #hidden = [batch size, src sent len, dec hid dim]\n","        #encoder_outputs = [batch size, src sent len, enc hid dim * 2]\n","        \n","        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n","        \n","        #energy = [batch size, src sent len, dec hid dim]\n","                \n","        energy = energy.permute(0, 2, 1)\n","        \n","        #energy = [batch size, dec hid dim, src sent len]\n","        \n","        #v = [dec hid dim]\n","        \n","        v = self.v.repeat(batch_size, 1).unsqueeze(1)\n","        \n","        #v = [batch size, 1, dec hid dim]\n","            \n","        attention = torch.bmm(v, energy).squeeze(1)\n","        \n","        #attention = [batch size, src sent len]\n","        \n","        attention = attention.masked_fill(mask == 0, -1e10)\n","        \n","        return F.softmax(attention, dim = 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cJ_NJ8u3gu6U","colab_type":"code","colab":{}},"source":["class Decoder(nn.Module):\n","    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n","        super().__init__()\n","\n","        self.emb_dim = emb_dim\n","        self.enc_hid_dim = enc_hid_dim\n","        self.dec_hid_dim = dec_hid_dim\n","        self.output_dim = output_dim\n","        self.dropout = dropout\n","        self.attention = attention\n","        \n","        self.embedding = nn.Embedding(output_dim, emb_dim)\n","        \n","        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n","        \n","        self.out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, input, hidden, encoder_outputs, mask):\n","             \n","        #input = [batch size]\n","        #hidden = [batch size, dec hid dim]\n","        #encoder_outputs = [src sent len, batch size, enc hid dim * 2]\n","        #mask = [batch size, src sent len]\n","        \n","        input = input.unsqueeze(0)\n","        \n","        #input = [1, batch size]\n","        \n","        embedded = self.dropout(self.embedding(input))\n","        \n","        #embedded = [1, batch size, emb dim]\n","        \n","        a = self.attention(hidden, encoder_outputs, mask)\n","                \n","        #a = [batch size, src sent len]\n","        \n","        a = a.unsqueeze(1)\n","        \n","        #a = [batch size, 1, src sent len]\n","        \n","        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n","        \n","        #encoder_outputs = [batch size, src sent len, enc hid dim * 2]\n","        \n","        weighted = torch.bmm(a, encoder_outputs)\n","        \n","        #weighted = [batch size, 1, enc hid dim * 2]\n","        \n","        weighted = weighted.permute(1, 0, 2)\n","        \n","        #weighted = [1, batch size, enc hid dim * 2]\n","        \n","        rnn_input = torch.cat((embedded, weighted), dim = 2)\n","        \n","        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n","            \n","        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n","        \n","        #output = [sent len, batch size, dec hid dim * n directions]\n","        #hidden = [n layers * n directions, batch size, dec hid dim]\n","        \n","        #sent len, n layers and n directions will always be 1 in this decoder, therefore:\n","        #output = [1, batch size, dec hid dim]\n","        #hidden = [1, batch size, dec hid dim]\n","        #this also means that output == hidden\n","        assert (output == hidden).all()\n","        \n","        embedded = embedded.squeeze(0)\n","        output = output.squeeze(0)\n","        weighted = weighted.squeeze(0)\n","        \n","        output = self.out(torch.cat((output, weighted, embedded), dim = 1))\n","        \n","        #output = [bsz, output dim]\n","        \n","        return output, hidden.squeeze(0), a.squeeze(1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G_FksK_Ygu6Y","colab_type":"code","colab":{}},"source":["class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder, pad_idx, sos_idx, eos_idx, device):\n","        super().__init__()\n","        \n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.pad_idx = pad_idx\n","        self.sos_idx = sos_idx\n","        self.eos_idx = eos_idx\n","        self.device = device\n","        \n","    def create_mask(self, src):\n","        mask = (src != self.pad_idx).permute(1, 0)\n","        return mask\n","        \n","    def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n","        \n","        #src = [src sent len, batch size]\n","        #src_len = [batch size]\n","        #trg = [trg sent len, batch size]\n","        #teacher_forcing_ratio is probability to use teacher forcing\n","        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n","        \n","        if trg is None:\n","            assert teacher_forcing_ratio == 0, \"Must be zero during inference\"\n","            inference = True\n","            trg = torch.zeros((100, src.shape[1])).long().fill_(self.sos_idx).to(src.device)\n","        else:\n","            inference = False\n","            \n","        batch_size = src.shape[1]\n","        max_len = trg.shape[0]\n","        trg_vocab_size = self.decoder.output_dim\n","        \n","        #tensor to store decoder outputs\n","        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n","        \n","        #tensor to store attention\n","        attentions = torch.zeros(max_len, batch_size, src.shape[0]).to(self.device)\n","        \n","        #encoder_outputs is all hidden states of the input sequence, back and forwards\n","        #hidden is the final forward and backward hidden states, passed through a linear layer\n","        encoder_outputs, hidden = self.encoder(src, src_len)\n","                \n","        #first input to the decoder is the <sos> tokens\n","        output = trg[0,:]\n","        \n","        mask = self.create_mask(src)\n","                \n","        #mask = [batch size, src sent len]\n","                \n","        for t in range(1, max_len):\n","            output, hidden, attention = self.decoder(output, hidden, encoder_outputs, mask)\n","            outputs[t] = output\n","            attentions[t] = attention\n","            teacher_force = random.random() < teacher_forcing_ratio\n","            top1 = output.max(1)[1]\n","            output = (trg[t] if teacher_force else top1)\n","            if inference and output.item() == self.eos_idx:\n","                return outputs[:t], attentions[:t]\n","            \n","        return outputs, attentions"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SEirKK34gu6c","colab_type":"code","colab":{}},"source":["INPUT_DIM = len(SRC.vocab)\n","OUTPUT_DIM = len(TRG.vocab)\n","ENC_EMB_DIM = 128\n","DEC_EMB_DIM = 128\n","ENC_HID_DIM = 100\n","DEC_HID_DIM = 100\n","ENC_DROPOUT = 0.8\n","DEC_DROPOUT = 0.8\n","PAD_IDX = SRC.vocab.stoi['<pad>']\n","SOS_IDX = TRG.vocab.stoi['<sos>']\n","EOS_IDX = TRG.vocab.stoi['<eos>']\n","\n","attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n","enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n","dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n","\n","model = Seq2Seq(enc, dec, PAD_IDX, SOS_IDX, EOS_IDX, device).to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8q_BhdXJgu6g","colab_type":"code","colab":{}},"source":["def init_weights(m):\n","    for name, param in m.named_parameters():\n","        if 'weight' in name:\n","            nn.init.normal_(param.data, mean=0, std=0.01)\n","        else:\n","            nn.init.constant_(param.data, 0)\n","            \n","model.apply(init_weights)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M5Cg8y0Fgu6j","colab_type":"code","outputId":"b051308d-803f-44ed-9f8a-ff839487ca9b","executionInfo":{"status":"ok","timestamp":1587821039929,"user_tz":-240,"elapsed":4518,"user":{"displayName":"Alexcei64rus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4SypAswQozU3-DGFu0VQyxwB_TSZLCZKDR1Z6Cg=s64","userId":"06079512506264468138"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'Модель содержит {count_parameters(model):,} параметров')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Модель содержит 615,651 параметров\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zzDccH0Ygu6n","colab_type":"text"},"source":["Then we define our optimizer and criterion. We have already initialized `PAD_IDX` when initializing the model, so we don't need to do it again."]},{"cell_type":"code","metadata":{"id":"w2cl68N2gu6o","colab_type":"code","colab":{}},"source":["optimizer = optim.Adam(model.parameters())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PbYoa65vgu6s","colab_type":"code","colab":{}},"source":["criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cY6tlNb6gu6w","colab_type":"code","colab":{}},"source":["def train(model, iterator, optimizer, criterion, clip):\n","    \n","    model.train()\n","    \n","    epoch_loss = 0\n","    \n","    for i, batch in enumerate(iterator):\n","        \n","        src, src_len = batch.src\n","        trg = batch.trg\n","        \n","        optimizer.zero_grad()\n","        \n","        output, attetion = model(src, src_len, trg, 0.4)\n","        \n","        #trg = [trg sent len, batch size]\n","        #output = [trg sent len, batch size, output dim]\n","        \n","        output = output[1:].view(-1, output.shape[-1])\n","        trg = trg[1:].view(-1)\n","        \n","        #trg = [(trg sent len - 1) * batch size]\n","        #output = [(trg sent len - 1) * batch size, output dim]\n","        \n","        loss = criterion(output, trg)\n","        \n","        loss.backward()\n","        \n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        \n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tds294Kdgu61","colab_type":"code","colab":{}},"source":["def evaluate(model, iterator, criterion):\n","    \n","    model.eval()\n","    \n","    epoch_loss = 0\n","    \n","    with torch.no_grad():\n","    \n","        for i, batch in enumerate(iterator):\n","\n","            src, src_len = batch.src\n","            trg = batch.trg\n","\n","            output, attention = model(src, src_len, trg, 0) #turn off teacher forcing\n","\n","            #trg = [trg sent len, batch size]\n","            #output = [trg sent len, batch size, output dim]\n","\n","            output = output[1:].view(-1, output.shape[-1])\n","            trg = trg[1:].view(-1)\n","\n","            #trg = [(trg sent len - 1) * batch size]\n","            #output = [(trg sent len - 1) * batch size, output dim]\n","\n","            loss = criterion(output, trg)\n","\n","            epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a1WaqI7Sgu65","colab_type":"code","colab":{}},"source":["def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"5wWH92J9gu69","colab_type":"code","colab":{}},"source":["N_EPOCHS = 50\n","CLIP = 1\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","    \n","    start_time = time.time()\n","    \n","    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n","    valid_loss = evaluate(model, valid_iterator, criterion)\n","    \n","    end_time = time.time()\n","    \n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'conala_model_attention_test.pt')\n","    \n","    print(f'Эпоха: {epoch+1:02} | Время: {epoch_mins}m {epoch_secs}s')\n","    print(f'Перплексия (обучение): {math.exp(train_loss):7.3f}')\n","    print(f'Перплексия (валидация): {math.exp(valid_loss):7.3f}')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sMGIR1a0gu7B","colab_type":"code","outputId":"0c0d450e-c692-4771-9499-81e221d6914d","executionInfo":{"status":"ok","timestamp":1587821506349,"user_tz":-240,"elapsed":2485,"user":{"displayName":"Alexcei64rus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4SypAswQozU3-DGFu0VQyxwB_TSZLCZKDR1Z6Cg=s64","userId":"06079512506264468138"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["model.load_state_dict(torch.load('conala_model_attention_test.pt'))\n","\n","test_loss = evaluate(model, test_iterator, criterion)\n","\n","print(f'Перплексия (валидация): {math.exp(test_loss):7.3f}')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Перплексия (валидация):  30.846\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ASI8w_Gqgu7E","colab_type":"text"},"source":["## Предсказание кода по вопросу"]},{"cell_type":"code","metadata":{"id":"KqYQbv8Bgu7F","colab_type":"code","colab":{}},"source":["def translate_sentence(model, sentence):\n","    model.eval()\n","    tokenized = tokenize_question(sentence) \n","    tokenized = ['<sos>'] + [t.lower() for t in tokenized] + ['<eos>']\n","    numericalized = [SRC.vocab.stoi[t] for t in tokenized] \n","    sentence_length = torch.LongTensor([len(numericalized)]).to(device) \n","    tensor = torch.LongTensor(numericalized).unsqueeze(1).to(device) \n","    translation_tensor_logits, attention = model(tensor, sentence_length, None, 0) \n","    translation_tensor = torch.argmax(translation_tensor_logits.squeeze(1), 1)\n","    translation = [TRG.vocab.itos[t] for t in translation_tensor]\n","    translation, attention = translation[1:], attention[1:]\n","    return translation, attention"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"srUpnPtvgu7N","colab_type":"code","colab":{}},"source":["def display_attention(candidate, translation, attention):\n","    \n","    fig = plt.figure(figsize=(10,10))\n","    ax = fig.add_subplot(111)\n","    \n","    attention = attention.squeeze(1).cpu().detach().numpy()\n","    \n","    cax = ax.matshow(attention, cmap='bone')\n","   \n","    ax.tick_params(labelsize=15)\n","    ax.set_xticklabels([''] + ['<sos>'] + [t.lower() for t in tokenize_question(candidate)] + ['<eos>'], \n","                       rotation=45)\n","    ax.set_yticklabels([''] + translation)\n","\n","    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n","\n","    plt.show()\n","    plt.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bXx_Q5kggu7Q","colab_type":"code","colab":{}},"source":["example_idx = 42\n","\n","src = ' '.join(vars(train_data.examples[example_idx])['src'])\n","trg = ' '.join(vars(train_data.examples[example_idx])['trg'])\n","\n","print(f'src = {src}')\n","print(f'trg = {trg}')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wc9Bgiifgu7T","colab_type":"code","colab":{}},"source":["translation, attention = translate_sentence(model, src)\n","\n","print('predicted trg = ', ' '.join(translation))\n","\n","display_attention(src, translation, attention)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rTUgEkiCgu7X","colab_type":"code","colab":{}},"source":["example_idx = 8\n","\n","src = ' '.join(vars(valid_data.examples[example_idx])['src'])\n","trg = ' '.join(vars(valid_data.examples[example_idx])['trg'])\n","\n","print(f'src = {src}')\n","print(f'trg = {trg}')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3lw3ppG6gu7a","colab_type":"code","colab":{}},"source":["translation, attention = translate_sentence(model, src)\n","\n","print('predicted trg = ', ' '.join(translation))\n","\n","display_attention(src, translation, attention)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pp0xZnb2gu7e","colab_type":"code","colab":{}},"source":["example_idx = 4\n","\n","src = ' '.join(vars(test_data.examples[example_idx])['src'])\n","trg = ' '.join(vars(test_data.examples[example_idx])['trg'])\n","\n","print(f'src = {src}')\n","print(f'trg = {trg}')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RinjrPjIgu7h","colab_type":"code","colab":{}},"source":["translation, attention = translate_sentence(model, src)\n","\n","print('predicted trg = ', ''.join(translation))\n","\n","display_attention(src, translation, attention)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sf5UoR6glmsp","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UNKdmkGSlm6h","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hmPbd1bItSXa","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a4GekTTilzEU","colab_type":"text"},"source":["# Домашняя работа"]},{"cell_type":"code","metadata":{"id":"gV42wM56lm-J","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":819},"outputId":"48b051e3-d0e4-4703-a7bb-c5e5c5381999","executionInfo":{"status":"ok","timestamp":1587827620158,"user_tz":-240,"elapsed":18590,"user":{"displayName":"Alexcei64rus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4SypAswQozU3-DGFu0VQyxwB_TSZLCZKDR1Z6Cg=s64","userId":"06079512506264468138"}}},"source":["from torchtext.datasets import TranslationDataset, Multi30k\n","\n","!python -m spacy download de_core_news_sm\n","\n","!python -m spacy download en_core_web_sm\n","\n","import en_core_web_sm\n","\n","import de_core_news_sm\n","\n","spacy_de = de_core_news_sm.load() \n","\n","spacy_en = en_core_web_sm.load() \n","\n","\n","def tokenize_de(text):\n","    return [tok.text for tok in spacy_de.tokenizer(text)][::-1]\n","\n","def tokenize_en(text):\n","    return [tok.text for tok in spacy_en.tokenizer(text)]\n","\n","\n","SRC = Field(tokenize = tokenize_de, \n","            init_token = '<sos>', \n","            eos_token = '<eos>', \n","            lower = True)\n","\n","TRG = Field(tokenize = tokenize_en, \n","            init_token = '<sos>', \n","            eos_token = '<eos>', \n","            lower = True)\n","\n","train_data, valid_data, test_data = Multi30k.splits(\n","    exts = ('.de', '.en'), \n","    fields = (SRC, TRG)\n",")"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: de_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz#egg=de_core_news_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n","Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.21.0)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (46.1.3)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.18.3)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.38.0)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.6.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.4.5.1)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.8)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.6.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.1.0)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('de_core_news_sm')\n","Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n","Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.21.0)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.38.0)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (46.1.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.3)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.1)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xFVzhftnlnJ5","colab_type":"code","outputId":"9cbe935c-4e39-4f20-a6ba-4f19de324384","executionInfo":{"status":"ok","timestamp":1587827620160,"user_tz":-240,"elapsed":2768,"user":{"displayName":"Alexcei64rus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4SypAswQozU3-DGFu0VQyxwB_TSZLCZKDR1Z6Cg=s64","userId":"06079512506264468138"}},"colab":{"base_uri":"https://localhost:8080/","height":105}},"source":["SRC.build_vocab([train_data.src], max_size=25000, min_freq=3)\n","print(SRC.vocab.freqs.most_common(20))\n","\n","\n","TRG.build_vocab([train_data.trg], min_freq=5)\n","print(TRG.vocab.freqs.most_common(20))\n","\n","print(f\"Уникальные токены в словаре интентов: {len(SRC.vocab)}\")\n","print(f\"Уникальные токены в словаре сниппетов: {len(TRG.vocab)}\")"],"execution_count":11,"outputs":[{"output_type":"stream","text":["[('.', 28820), ('ein', 18850), ('einem', 13711), ('in', 11892), ('eine', 9908), (',', 8938), ('und', 8925), ('mit', 8843), ('auf', 8745), ('mann', 7805), ('einer', 6765), ('der', 4988), ('frau', 4186), ('die', 3948), ('zwei', 3872), ('einen', 3479), ('im', 3106), ('an', 3062), ('von', 2363), ('sich', 2273)]\n","[('a', 49165), ('.', 27622), ('in', 14886), ('the', 10955), ('on', 8035), ('man', 7781), ('is', 7525), ('and', 7379), ('of', 6871), ('with', 6179), ('woman', 3973), (',', 3962), ('two', 3885), ('are', 3716), ('to', 3128), ('people', 3122), ('at', 2927), ('an', 2861), ('wearing', 2623), ('shirt', 2324)]\n","Уникальные токены в словаре интентов: 5376\n","Уникальные токены в словаре сниппетов: 3270\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XxHnv2ZNlnNV","colab_type":"code","outputId":"2e8c5e7e-e5d7-4f2c-d64f-03cb113e1462","executionInfo":{"status":"ok","timestamp":1587827622934,"user_tz":-240,"elapsed":650,"user":{"displayName":"Alexcei64rus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4SypAswQozU3-DGFu0VQyxwB_TSZLCZKDR1Z6Cg=s64","userId":"06079512506264468138"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["print(f\"Размер обучающей выборки: {len(train_data.examples)}\")\n","print(f\"Размер валидационной выборки: {len(valid_data.examples)}\")\n","print(f\"Размер тестовой выборки: {len(test_data.examples)}\")"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Размер обучающей выборки: 29000\n","Размер валидационной выборки: 1014\n","Размер тестовой выборки: 1000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NWsOKbfrnIcU","colab_type":"code","colab":{}},"source":["BATCH_SIZE = 4\n","\n","train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n","    (train_data, valid_data, test_data), \n","     batch_size = BATCH_SIZE,\n","     sort_within_batch = True,\n","     sort_key = lambda x : len(x.src),\n","     device = device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"55l4J773nQDT","colab_type":"code","colab":{}},"source":["class Encoder1(nn.Module):\n","    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n","        super().__init__()\n","        \n","        self.input_dim = input_dim\n","        self.emb_dim = emb_dim\n","        self.enc_hid_dim = enc_hid_dim\n","        self.dec_hid_dim = dec_hid_dim\n","        self.dropout = dropout\n","        \n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","        \n","        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n","        \n","        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, src, src_len):\n","        \n","        #src = [src sent len, batch size]\n","        #src_len = [src sent len]\n","        \n","        embedded = self.dropout(self.embedding(src))\n","        \n","        #embedded = [src sent len, batch size, emb dim]\n","        \n","        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len)\n","        \n","        packed_outputs, hidden = self.rnn(packed_embedded)\n","                     \n","        #packed_outputs is a packed sequence containing all hidden states\n","        #hidden is now from the final non-padded element in the batch\n","            \n","        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs) \n","            \n","        #outputs is now a non-packed sequence, all hidden states obtained\n","        #  when the input is a pad token are all zeros\n","            \n","        #outputs = [sent len, batch size, hid dim * num directions]\n","        #hidden = [n layers * num directions, batch size, hid dim]\n","        \n","        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n","        #outputs are always from the last layer\n","        \n","        #hidden [-2, :, : ] is the last of the forwards RNN \n","        #hidden [-1, :, : ] is the last of the backwards RNN\n","        \n","        #initial decoder hidden is final hidden state of the forwards and backwards \n","        #  encoder RNNs fed through a linear layer\n","        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n","        \n","        #outputs = [sent len, batch size, enc hid dim * 2]\n","        #hidden = [batch size, dec hid dim]\n","        \n","        return outputs, hidden"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CqvI98KWroP8","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","def train(model, iterator, optimizer, criterion, clip):\n","    \n","    model.train()\n","    \n","    epoch_loss = 0\n","    \n","    for i, batch in enumerate(iterator):\n","        \n","        # src, src_len = batch.src # add 0\n","        src = batch.src # add 1\n","        src_len_np = np.full((src.shape[1]), src.shape[0]) # add 2\n","        src_len = torch.tensor(src_len_np) # add 3\n","        trg = batch.trg\n","        \n","        optimizer.zero_grad()\n","        \n","        output, attetion = model(src, src_len, trg, 0.4)\n","        \n","        #trg = [trg sent len, batch size]\n","        #output = [trg sent len, batch size, output dim]\n","        \n","        output = output[1:].view(-1, output.shape[-1])\n","        trg = trg[1:].view(-1)\n","        \n","        #trg = [(trg sent len - 1) * batch size]\n","        #output = [(trg sent len - 1) * batch size, output dim]\n","        \n","        loss = criterion(output, trg)\n","        \n","        loss.backward()\n","        \n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        \n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tbr01Ti9t7a7","colab_type":"code","colab":{}},"source":["def evaluate(model, iterator, criterion):\n","    \n","    model.eval()\n","    \n","    epoch_loss = 0\n","    \n","    with torch.no_grad():\n","    \n","        for i, batch in enumerate(iterator):\n","\n","            # изменения здесь\n","            #src, src_len = batch.src\n","            src = batch.src\n","            src_len_np = np.full((src.shape[1]), src.shape[0])\n","            src_len = torch.tensor(src_len_np)\n","            trg = batch.trg\n","\n","            output, attention = model(src, src_len, trg, 0) #turn off teacher forcing\n","\n","            #trg = [trg sent len, batch size]\n","            #output = [trg sent len, batch size, output dim]\n","\n","            output = output[1:].view(-1, output.shape[-1])\n","            trg = trg[1:].view(-1)\n","\n","            #trg = [(trg sent len - 1) * batch size]\n","            #output = [(trg sent len - 1) * batch size, output dim]\n","\n","            loss = criterion(output, trg)\n","\n","            epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nsgjjLgXnbsX","colab_type":"code","colab":{}},"source":["INPUT_DIM = len(SRC.vocab)\n","OUTPUT_DIM = len(TRG.vocab)\n","ENC_EMB_DIM = 128\n","DEC_EMB_DIM = 128\n","ENC_HID_DIM = 100\n","DEC_HID_DIM = 100\n","ENC_DROPOUT = 0.8\n","DEC_DROPOUT = 0.8\n","PAD_IDX = SRC.vocab.stoi['<pad>']\n","SOS_IDX = TRG.vocab.stoi['<sos>']\n","EOS_IDX = TRG.vocab.stoi['<eos>']\n","\n","attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n","enc = Encoder1(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n","dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n","\n","model = Seq2Seq(enc, dec, PAD_IDX, SOS_IDX, EOS_IDX, device).to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kekU4VPHnnPb","colab_type":"code","outputId":"7dc619cb-6f74-487a-e806-7a9d9e359713","executionInfo":{"status":"ok","timestamp":1587827671572,"user_tz":-240,"elapsed":667,"user":{"displayName":"Alexcei64rus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4SypAswQozU3-DGFu0VQyxwB_TSZLCZKDR1Z6Cg=s64","userId":"06079512506264468138"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["def init_weights(m):\n","    for name, param in m.named_parameters():\n","        if 'weight' in name:\n","            nn.init.normal_(param.data, mean=0, std=0.01)\n","        else:\n","            nn.init.constant_(param.data, 0)\n","            \n","model.apply(init_weights)"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Seq2Seq(\n","  (encoder): Encoder1(\n","    (embedding): Embedding(5376, 128)\n","    (rnn): GRU(128, 100, bidirectional=True)\n","    (fc): Linear(in_features=200, out_features=100, bias=True)\n","    (dropout): Dropout(p=0.8, inplace=False)\n","  )\n","  (decoder): Decoder(\n","    (attention): Attention(\n","      (attn): Linear(in_features=300, out_features=100, bias=True)\n","    )\n","    (embedding): Embedding(3270, 128)\n","    (rnn): GRU(328, 100)\n","    (out): Linear(in_features=428, out_features=3270, bias=True)\n","    (dropout): Dropout(p=0.8, inplace=False)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"-8aPms2ynsIc","colab_type":"code","outputId":"963e0cb8-9ec9-4776-fc32-186159a26a51","executionInfo":{"status":"ok","timestamp":1587827675731,"user_tz":-240,"elapsed":683,"user":{"displayName":"Alexcei64rus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4SypAswQozU3-DGFu0VQyxwB_TSZLCZKDR1Z6Cg=s64","userId":"06079512506264468138"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'Модель содержит {count_parameters(model):,} параметров')"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Модель содержит 2,826,818 параметров\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cqV2BXt5y7UC","colab_type":"code","outputId":"b4988b46-1f7e-4b64-dbda-5ac280e2c283","executionInfo":{"status":"ok","timestamp":1587827678402,"user_tz":-240,"elapsed":793,"user":{"displayName":"Alexcei64rus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4SypAswQozU3-DGFu0VQyxwB_TSZLCZKDR1Z6Cg=s64","userId":"06079512506264468138"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["for i, batch in enumerate(train_iterator):\n","  src = batch.src\n","  print(src.shape[0])\n","  print(torch.tensor(src.shape[0]))\n","  break"],"execution_count":23,"outputs":[{"output_type":"stream","text":["12\n","tensor(12)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vM2PdSEMnsPr","colab_type":"code","outputId":"296cdaf9-8f52-4cba-b906-385770080d6e","executionInfo":{"status":"error","timestamp":1587829813018,"user_tz":-240,"elapsed":2091571,"user":{"displayName":"Alexcei64rus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4SypAswQozU3-DGFu0VQyxwB_TSZLCZKDR1Z6Cg=s64","userId":"06079512506264468138"}},"colab":{"base_uri":"https://localhost:8080/","height":598}},"source":["N_EPOCHS = 50\n","CLIP = 1\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","    \n","    start_time = time.time()\n","    \n","    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n","    valid_loss = evaluate(model, valid_iterator, criterion)\n","    \n","    end_time = time.time()\n","    \n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'conala_model_attention_test.pt')\n","    \n","    print(f'Эпоха: {epoch+1:02} | Время: {epoch_mins}m {epoch_secs}s')\n","    print(f'Перплексия (обучение): {math.exp(train_loss):7.3f}')\n","    print(f'Перплексия (валидация): {math.exp(valid_loss):7.3f}')"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Эпоха: 01 | Время: 8m 30s\n","Перплексия (обучение):  61.906\n","Перплексия (валидация):  36.375\n","Эпоха: 02 | Время: 8m 31s\n","Перплексия (обучение):  27.920\n","Перплексия (валидация):  26.551\n","Эпоха: 03 | Время: 8m 25s\n","Перплексия (обучение):  20.868\n","Перплексия (валидация):  24.596\n","Эпоха: 04 | Время: 8m 28s\n","Перплексия (обучение):  17.776\n","Перплексия (валидация):  22.094\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-0e88092933c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-9cacf373c03c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"yBMDI6XKnsVQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"71eac4b9-d111-4359-b30a-de273b0f064f","executionInfo":{"status":"ok","timestamp":1587831225701,"user_tz":-240,"elapsed":6532,"user":{"displayName":"Alexcei64rus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4SypAswQozU3-DGFu0VQyxwB_TSZLCZKDR1Z6Cg=s64","userId":"06079512506264468138"}}},"source":["model.load_state_dict(torch.load('conala_model_attention_test.pt'))\n","\n","test_loss = evaluate(model, test_iterator, criterion)\n","\n","print(f'Перплексия (тест): {math.exp(test_loss):7.3f}')"],"execution_count":58,"outputs":[{"output_type":"stream","text":["Перплексия (тест):  22.667\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i1ps19sUnsNJ","colab_type":"code","colab":{}},"source":["def translate_sentence(model, sentence):\n","    model.eval()\n","    tokenized = tokenize_de(sentence) \n","    tokenized = ['<sos>'] + [t.lower() for t in tokenized] + ['<eos>']\n","    numericalized = [SRC.vocab.stoi[t] for t in tokenized] \n","    sentence_length = torch.LongTensor([len(numericalized)]).to(device) \n","    tensor = torch.LongTensor(numericalized).unsqueeze(1).to(device) \n","    translation_tensor_logits, attention = model(tensor, sentence_length, None, 0) \n","    translation_tensor = torch.argmax(translation_tensor_logits.squeeze(1), 1)\n","    translation = [TRG.vocab.itos[t] for t in translation_tensor]\n","    translation, attention = translation[1:], attention[1:]\n","    return translation, attention"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6dEYhoFTBnn1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"513ae1ae-c930-4848-f911-6d242058d585","executionInfo":{"status":"ok","timestamp":1587830665273,"user_tz":-240,"elapsed":609,"user":{"displayName":"Alexcei64rus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4SypAswQozU3-DGFu0VQyxwB_TSZLCZKDR1Z6Cg=s64","userId":"06079512506264468138"}}},"source":["a, _ = translate_sentence(model,\"ein mann telefoniert in einem unaufgeräumten büro\")\n","print(\" \".join(a))"],"execution_count":55,"outputs":[{"output_type":"stream","text":["a man is talking in a <unk> room .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lRF05X2IBrz0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"dc981bce-b371-4241-b321-14ec7d2cf440","executionInfo":{"status":"ok","timestamp":1587830378920,"user_tz":-240,"elapsed":655,"user":{"displayName":"Alexcei64rus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4SypAswQozU3-DGFu0VQyxwB_TSZLCZKDR1Z6Cg=s64","userId":"06079512506264468138"}}},"source":["a, _ = translate_sentence(model,\"Ich liebe dich\")\n","print(\" \".join(a))"],"execution_count":46,"outputs":[{"output_type":"stream","text":["<unk> <unk> <unk> <unk> <unk> .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4kt0eVPmBr-0","colab_type":"code","colab":{}},"source":["def display_attention(candidate, translation, attention):\n","    \n","    fig = plt.figure(figsize=(10,10))\n","    ax = fig.add_subplot(111)\n","    \n","    attention = attention.squeeze(1).cpu().detach().numpy()\n","    \n","    cax = ax.matshow(attention, cmap='bone')\n","   \n","    ax.tick_params(labelsize=15)\n","    ax.set_xticklabels([''] + ['<sos>'] + [t.lower() for t in tokenize_de(candidate)] + ['<eos>'], \n","                       rotation=45)\n","    ax.set_yticklabels([''] + translation)\n","\n","    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n","\n","    plt.show()\n","    plt.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iUsOv4v2BsGo","colab_type":"code","colab":{}},"source":["example_idx = 2\n","\n","src = ' '.join(vars(train_data.examples[example_idx])['src'][::-1])\n","trg = ' '.join(vars(train_data.examples[example_idx])['trg'])\n","\n","print(f'src = {src}')\n","print(f'trg = {trg}')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xVPgLZokBsKd","colab_type":"code","colab":{}},"source":["translation, attention = translate_sentence(model, src)\n","\n","print('predicted trg = ', ' '.join(translation))\n","\n","display_attention(src, translation, attention)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qQbCuALYBsQI","colab_type":"code","colab":{}},"source":["example_idx = 8\n","\n","src = ' '.join(vars(valid_data.examples[example_idx])['src'][::-1])\n","trg = ' '.join(vars(valid_data.examples[example_idx])['trg'])\n","\n","print(f'src = {src}')\n","print(f'trg = {trg}')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oiB6EZvYB237","colab_type":"code","colab":{}},"source":["translation, attention = translate_sentence(model, src)\n","\n","print('predicted trg = ', ' '.join(translation))\n","\n","display_attention(src, translation, attention)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZoQC_dX9B3qO","colab_type":"code","colab":{}},"source":["example_idx = 4\n","\n","src = ' '.join(vars(test_data.examples[example_idx])['src'][::-1])\n","trg = ' '.join(vars(test_data.examples[example_idx])['trg'])\n","\n","print(f'src = {src}')\n","print(f'trg = {trg}')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MXtSN_T_B6ja","colab_type":"code","colab":{}},"source":["translation, attention = translate_sentence(model, src)\n","\n","print('predicted trg = ', ''.join(translation))\n","\n","display_attention(src, translation, attention)"],"execution_count":0,"outputs":[]}]}