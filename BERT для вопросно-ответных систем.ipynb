{"nbformat":4,"nbformat_minor":0,"metadata":{"hide_input":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"toc":{"colors":{"hover_highlight":"#DAA520","running_highlight":"#FF0000","selected_highlight":"#FFD700"},"moveMenuLeft":true,"nav_menu":{"height":"48px","width":"252px"},"navigate_menu":true,"number_sections":true,"sideBar":true,"threshold":4,"toc_cell":false,"toc_section_display":"block","toc_window_display":false},"colab":{"name":"BERT для вопросно-ответных систем.ipynb","provenance":[{"file_id":"https://github.com/Samsung-IT-Academy/stepik-dl-nlp/blob/master/task10_bert_squad.ipynb","timestamp":1587756877700}],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"kjJr8ur8rwMP","colab_type":"text"},"source":["## BERT для вопросно-ответных систем"]},{"cell_type":"code","metadata":{"id":"4WdVYgdPrwMR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":241},"outputId":"4118be9d-d456-46b5-f0b3-00a5eef6f2b6","executionInfo":{"status":"ok","timestamp":1587757059262,"user_tz":-240,"elapsed":2973,"user":{"displayName":"Alexcei64rus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4SypAswQozU3-DGFu0VQyxwB_TSZLCZKDR1Z6Cg=s64","userId":"06079512506264468138"}}},"source":["# Если Вы запускаете ноутбук на colab или kaggle,\n","# выполните следующие строчки, чтобы подгрузить библиотеку dlnlputils:\n","\n","!git clone https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git && pip install -r stepik-dl-nlp/requirements.txt\n","import sys; sys.path.append('./stepik-dl-nlp')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["  Building wheel for ufal.udpipe (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ufal.udpipe: filename=ufal.udpipe-1.2.0.3-cp36-cp36m-linux_x86_64.whl size=5625250 sha256=ddb4ffe340f4c433ebf91a1881d012f14696c97ddbe59fbe6090567501ed281f\n","  Stored in directory: /root/.cache/pip/wheels/0c/9d/db/6d3404c33da5b7adb6c6972853efb6a27649d3ba15f7e9bebb\n","  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for intervaltree: filename=intervaltree-3.0.2-cp36-none-any.whl size=25791 sha256=a0c4629fc5d97276727055bee5266017b3b91f7351a1b9d75a32da29a701d66e\n","  Stored in directory: /root/.cache/pip/wheels/08/99/c0/5a5942f5b9567c59c14aac76f95a70bf11dccc71240b91ebf5\n","Successfully built ufal.udpipe intervaltree\n","Installing collected packages: ufal.udpipe, spacy-udpipe, dawg-python, pymorphy2-dicts, pymorphy2, intervaltree, ipymarkup, youtokentome, pyconll\n","  Found existing installation: intervaltree 2.1.0\n","    Uninstalling intervaltree-2.1.0:\n","      Successfully uninstalled intervaltree-2.1.0\n","Successfully installed dawg-python-0.7.2 intervaltree-3.0.2 ipymarkup-0.7.0 pyconll-2.2.1 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985 spacy-udpipe-0.2.1 ufal.udpipe-1.2.0.3 youtokentome-1.0.6\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"g7m9LjbzrwMX","colab_type":"text"},"source":["Скачайте датасет (SQuAD) [отсюда](https://rajpurkar.github.io/SQuAD-explorer/). Для выполенения семинара Вам понадобятся файлы `train-v2.0.json` и `dev-v2.0.json`."]},{"cell_type":"markdown","metadata":{"id":"3juEeklyrwMY","colab_type":"text"},"source":["Склонируйте репозиторий https://github.com/huggingface/transformers (воспользуйтесь скриптом `clone_pytorch_transformers.sh`) и положите путь до папки `examples` в переменную `PATH_TO_EXAMPLES`. "]},{"cell_type":"code","metadata":{"id":"XOgf1utqtxjg","colab_type":"code","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":74},"outputId":"d113c4fc-94f6-49b3-d6ff-8bbdf370842f","executionInfo":{"status":"ok","timestamp":1587757952906,"user_tz":-240,"elapsed":91564,"user":{"displayName":"Alexcei64rus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4SypAswQozU3-DGFu0VQyxwB_TSZLCZKDR1Z6Cg=s64","userId":"06079512506264468138"}}},"source":["from google.colab import files\n","\n","file = files.upload() # очень долго!!"],"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-19363ef6-46b4-4a9c-8472-c265cc2ccd31\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-19363ef6-46b4-4a9c-8472-c265cc2ccd31\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving dev-v2.0.json to dev-v2.0.json\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9TOYzzt9zGWH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"15d478e3-49ee-422e-8833-bcfda65c3db7","executionInfo":{"status":"ok","timestamp":1587758813696,"user_tz":-240,"elapsed":4314,"user":{"displayName":"Alexcei64rus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4SypAswQozU3-DGFu0VQyxwB_TSZLCZKDR1Z6Cg=s64","userId":"06079512506264468138"}}},"source":["!git clone https://github.com/huggingface/transformers"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Cloning into 'transformers'...\n","remote: Enumerating objects: 16, done.\u001b[K\n","remote: Counting objects:   6% (1/16)\u001b[K\rremote: Counting objects:  12% (2/16)\u001b[K\rremote: Counting objects:  18% (3/16)\u001b[K\rremote: Counting objects:  25% (4/16)\u001b[K\rremote: Counting objects:  31% (5/16)\u001b[K\rremote: Counting objects:  37% (6/16)\u001b[K\rremote: Counting objects:  43% (7/16)\u001b[K\rremote: Counting objects:  50% (8/16)\u001b[K\rremote: Counting objects:  56% (9/16)\u001b[K\rremote: Counting objects:  62% (10/16)\u001b[K\rremote: Counting objects:  68% (11/16)\u001b[K\rremote: Counting objects:  75% (12/16)\u001b[K\rremote: Counting objects:  81% (13/16)\u001b[K\rremote: Counting objects:  87% (14/16)\u001b[K\rremote: Counting objects:  93% (15/16)\u001b[K\rremote: Counting objects: 100% (16/16)\u001b[K\rremote: Counting objects: 100% (16/16), done.\u001b[K\n","remote: Compressing objects: 100% (12/12), done.\u001b[K\n","remote: Total 24662 (delta 4), reused 7 (delta 2), pack-reused 24646\u001b[K\n","Receiving objects: 100% (24662/24662), 14.91 MiB | 23.56 MiB/s, done.\n","Resolving deltas: 100% (17332/17332), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BKrCY5xTrwMZ","colab_type":"code","colab":{}},"source":["PATH_TO_TRANSFORMERS_REPO = '../transformers/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hUO5FgxZrwMd","colab_type":"code","colab":{}},"source":["import os\n","os.environ['PATH_TO_TRANSFORMER_REPO'] = PATH_TO_TRANSFORMERS_REPO\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mVZdq-C8rwMi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"0a72b8ae-5721-4a16-b18e-e0ed568336d5","executionInfo":{"status":"ok","timestamp":1587758013696,"user_tz":-240,"elapsed":2051,"user":{"displayName":"Alexcei64rus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4SypAswQozU3-DGFu0VQyxwB_TSZLCZKDR1Z6Cg=s64","userId":"06079512506264468138"}}},"source":["! bash clone_pytorch_transformers.sh $PATH_TO_TRANSFORMERS_REPO"],"execution_count":8,"outputs":[{"output_type":"stream","text":["bash: clone_pytorch_transformers.sh: No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x5jhyLVlrwMn","colab_type":"code","colab":{}},"source":["import sys\n","\n","PATH_TO_EXAMPLES = os.path.join(PATH_TO_TRANSFORMERS_REPO, 'examples')\n","sys.path.append(PATH_TO_EXAMPLES)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6A2xFacB0zrD","colab_type":"code","colab":{}},"source":["!cp transformers/templates/adding_a_new_example_script/utils_xxx.py  transformers/examples"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AC7Z-idN2Ec1","colab_type":"code","colab":{}},"source":["!pip install sacremoses"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ueHfobE72NOs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":731},"outputId":"1e9cc4f8-f7f9-48fd-9448-7e8b3ce5b958","executionInfo":{"status":"ok","timestamp":1587759606586,"user_tz":-240,"elapsed":1893,"user":{"displayName":"Alexcei64rus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4SypAswQozU3-DGFu0VQyxwB_TSZLCZKDR1Z6Cg=s64","userId":"06079512506264468138"}}},"source":["!env"],"execution_count":40,"outputs":[{"output_type":"stream","text":["CUDNN_VERSION=7.6.5.32\n","LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n","_=/usr/bin/env\n","LANG=en_US.UTF-8\n","HOSTNAME=18b0c9ac1f60\n","OLDPWD=/\n","CLOUDSDK_CONFIG=/content/.config\n","KMP_INIT_AT_FORK=FALSE\n","NVIDIA_VISIBLE_DEVICES=all\n","DATALAB_SETTINGS_OVERRIDES={\"kernelManagerProxyPort\":6000,\"kernelManagerProxyHost\":\"172.28.0.3\",\"jupyterArgs\":[\"--ip=\\\"172.28.0.2\\\"\"]}\n","ENV=/root/.bashrc\n","PAGER=cat\n","NCCL_VERSION=2.4.8\n","TF_FORCE_GPU_ALLOW_GROWTH=true\n","JPY_PARENT_PID=18\n","NO_GCE_CHECK=True\n","PWD=/content\n","HOME=/root\n","LAST_FORCED_REBUILD=20200316\n","CLICOLOR=1\n","DEBIAN_FRONTEND=noninteractive\n","LIBRARY_PATH=/usr/local/cuda/lib64/stubs\n","GCE_METADATA_TIMEOUT=0\n","GLIBCPP_FORCE_NEW=1\n","TBE_CREDS_ADDR=172.28.0.1:8008\n","TERM=xterm-color\n","SHELL=/bin/bash\n","GCS_READ_CACHE_BLOCK_SIZE_MB=16\n","PYTHONWARNINGS=ignore:::pip._internal.cli.base_command\n","MPLBACKEND=module://ipykernel.pylab.backend_inline\n","CUDA_PKG_VERSION=10-1=10.1.243-1\n","CUDA_VERSION=10.1.243\n","PATH_TO_TRANSFORMER_REPO=../transformers/\n","NVIDIA_DRIVER_CAPABILITIES=compute,utility\n","SHLVL=2\n","PYTHONPATH=/env/python\n","NVIDIA_REQUIRE_CUDA=cuda>=10.1 brand=tesla,driver>=384,driver<385 brand=tesla,driver>=396,driver<397 brand=tesla,driver>=410,driver<411\n","COLAB_GPU=0\n","GLIBCXX_FORCE_NEW=1\n","PATH=/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin\n","LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4\n","GIT_PAGER=cat\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"Ge_kANuKrwMr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":367},"outputId":"c0a1c36e-348d-4f16-b881-37a32c1d7906","executionInfo":{"status":"error","timestamp":1587759578724,"user_tz":-240,"elapsed":703,"user":{"displayName":"Alexcei64rus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4SypAswQozU3-DGFu0VQyxwB_TSZLCZKDR1Z6Cg=s64","userId":"06079512506264468138"}}},"source":["import torch\n","import tqdm\n","import json\n","import regex \n","import sacremoses\n","\n","from run_squad import train, load_and_cache_examples\n","\n","from utils_xxx import (read_squad_examples, convert_examples_to_features,\n","                         RawResult, write_predictions,\n","                         RawResultExtended, write_predictions_extended)\n","\n","\n","\n","from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n","\n","from transformers import (WEIGHTS_NAME, BertConfig, XLNetConfig, XLMConfig,\n","                          BertForQuestionAnswering, BertTokenizer)\n","\n","from utils_squad_evaluate import EVAL_OPTS, main as evaluate_on_squad\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"execution_count":39,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-39-968bb94ac6b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msacremoses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrun_squad\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_and_cache_examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m from utils_xxx import (read_squad_examples, convert_examples_to_features,\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'run_squad'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"qlqUTIt7rwMx","colab_type":"code","colab":{}},"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True, do_basic_tokenize=True)\n","model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ctsMAkXTrwM1","colab_type":"code","colab":{}},"source":["# если Вы не хотите запускать файн-тюнинг, пропустите блок \"Дообучение\",\n","# подгрузите веса уже дообученной модели и переходите к блоку \"Оценка качества\"\n","\n","# скачайте веса с Google-диска и положите их в папку models\n","# https://drive.google.com/drive/folders/1-DR30q7MF-gZ51TDx596dAOhgh-uOAPj?usp=sharing"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yYHQFYqrrwM6","colab_type":"code","colab":{}},"source":["if torch.cuda.is_available():\n","    model.cuda()\n","    model.load_state_dict(torch.load('models/bert_squad_1epoch.pt')) # если у вас есть GPU\n","else:\n","    model.load_state_dict(torch.load('models/bert_squad_1epoch.pt', map_location=device)) # если GPU нет"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QI79tPO2rwM_","colab_type":"text"},"source":["### Дообучение"]},{"cell_type":"code","metadata":{"id":"JtTmsV0XrwNA","colab_type":"code","colab":{}},"source":["# !pip install dataclasses\n","from dataclasses import dataclass\n","\n","@dataclass\n","class TRAIN_OPTS:\n","    train_file : str = 'train-v2.0.json'    # SQuAD json-файл для обучения\n","    predict_file : str = 'dev-v2.0.json'    # SQuAD json-файл для тестирования\n","    model_type : str = 'bert'               # тип модели (может быть  'bert', 'xlnet', 'xlm', 'distilbert')\n","    model_name_or_path : str = 'bert-base-uncased' # путь до предобученной модели или название модели из ALL_MODELS\n","    output_dir : str = '/tmp' # путь до директории, где будут храниться чекпоинты и предсказания модели\n","    device : str = 'cuda' # cuda или cpu\n","    n_gpu : int = 1 # количество gpu для обучения\n","    cache_dir : str = '' # где хранить предобученные модели, загруженные с s3\n","        \n","    # Если true, то в датасет будут включены вопросы, на которые нет ответов.\n","    version_2_with_negative : bool = True\n","    # Если (null_score - best_non_null) больше, чем порог, предсказывать null.\n","    null_score_diff_threshold : float = 0.0\n","    # Максимальная длина входной последовательности после WordPiece токенизации. Sequences \n","    # Последовательности длиннее будут укорочены, для более коротких последовательностей будет использован паддинг\n","    max_seq_length : int = 384\n","    # Сколько stride использовать при делении длинного документа на чанки\n","    doc_stride : int = 128\n","    # Максимальное количество токенов в вопросе. Более длинные вопросы будут укорочены до этой длины\n","    max_query_length : int = 128 #\n","        \n","    do_train : bool = True\n","    do_eval : bool = True\n","        \n","    # Запускать ли evaluation на каждом logging_step\n","    evaluate_during_training : bool = True\n","    # Должно быть True, если Вы используете uncased модели\n","    do_lower_case : bool = True #\n","    \n","    per_gpu_train_batch_size : int = 8 # размер батча для обучения\n","    per_gpu_eval_batch_size : int = 8 # размер батча для eval\n","    learning_rate : float = 5e-5 # learning rate\n","    gradient_accumulation_steps : int = 1 # количество шагов, которые нужно сделать перед backward/update pass\n","    weight_decay : float = 0.0 # weight decay\n","    adam_epsilon : float = 1e-8 # эпсилон для Adam\n","    max_grad_norm : float = 1.0 # максимальная норма градиента\n","    num_train_epochs : float = 5.0 # количество эпох на обучение\n","    max_steps : int = -1 # общее количество шагов на обучение (override num_train_epochs)\n","    warmup_steps : int = 0 # warmup \n","    n_best_size : int = 5 # количество ответов, которые надо сгенерировать для записи в nbest_predictions.json\n","    max_answer_length : int = 30 # максимально возможная длина ответа\n","    verbose_logging : bool = True # печатать или нет warnings, относящиеся к обработке данных\n","    logging_steps : int = 5000 # логировать каждые X шагов\n","    save_steps : int = 5000 # сохранять чекпоинт каждые X шагов\n","        \n","    # Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\n","    eval_all_checkpoints : bool = True\n","    no_cuda : bool = False # не использовать CUDA\n","    overwrite_output_dir : bool = True # переписывать ли содержимое директории с выходными файлами\n","    overwrite_cache : bool = True # переписывать ли закешированные данные для обучения и evaluation\n","    seed : int = 42 # random seed\n","    local_rank : int = -1 # local rank для распределенного обучения на GPU\n","    fp16 : bool = False # использовать ли 16-bit (mixed) precision (через NVIDIA apex) вместо 32-bit\"\n","    # Apex AMP optimization level: ['O0', 'O1', 'O2', and 'O3'].\n","    # Подробнее тут: https://nvidia.github.io/apex/amp.html\n","    fp16_opt_level : str = '01'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"njWHaMkqrwNE","colab_type":"code","colab":{}},"source":["ALL_MODELS = sum((tuple(conf.pretrained_config_archive_map.keys()) \\\n","                  for conf in (BertConfig, XLNetConfig, XLMConfig)), ())\n","ALL_MODELS"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"rdH9YnHPrwNL","colab_type":"code","colab":{}},"source":["args = TRAIN_OPTS()\n","train_dataset = load_and_cache_examples(args, tokenizer, evaluate=False, output_examples=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"5k5W5JpPrwNO","colab_type":"code","colab":{}},"source":["train(args, train_dataset, model, tokenizer)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xZtUb8vQrwNS","colab_type":"text"},"source":["Сохраняем веса дообученной модели на диск, чтобы в следующий раз не обучать модель заново."]},{"cell_type":"code","metadata":{"id":"Lg6plE8srwNS","colab_type":"code","colab":{}},"source":["torch.save(model.state_dict(), 'models/bert_squad_final_5epoch.pt')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JMEtXhs9rwNW","colab_type":"text"},"source":["Подгрузить веса модели можно так:"]},{"cell_type":"code","metadata":{"id":"97CWmhvYrwNX","colab_type":"code","colab":{}},"source":["model.load_state_dict(torch.load('models/bert_squad_5epochs.pt'))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YhM247jHrwNa","colab_type":"text"},"source":["### Оценка качества работы модели"]},{"cell_type":"code","metadata":{"id":"2kJhZg7FrwNb","colab_type":"code","colab":{}},"source":["PATH_TO_DEV_SQUAD = 'dev-v2.0.json'\n","PATH_TO_SMALL_DEV_SQUAD = 'small_dev-v2.0.json'\n","\n","with open(PATH_TO_DEV_SQUAD, 'r') as iofile:\n","    full_sample = json.load(iofile)\n","    \n","small_sample = {\n","    'version': full_sample['version'],\n","    'data': full_sample['data'][:1]\n","}\n","\n","with open(PATH_TO_SMALL_DEV_SQUAD, 'w') as iofile:\n","    json.dump(small_sample, iofile)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EG893izqrwNe","colab_type":"code","colab":{}},"source":["max_seq_length = 384\n","outside_pos = max_seq_length + 10\n","doc_stride = 128\n","max_query_length = 64\n","max_answer_length = 30"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"_AOLQY8ErwNi","colab_type":"code","colab":{}},"source":["examples = read_squad_examples(\n","    input_file=PATH_TO_SMALL_DEV_SQUAD,\n","    is_training=False,\n","    version_2_with_negative=True)\n","\n","features = convert_examples_to_features(\n","    examples=examples,\n","    tokenizer=tokenizer,\n","    max_seq_length=max_seq_length,\n","    doc_stride=doc_stride,\n","    max_query_length=max_query_length,\n","    is_training=False,\n","    cls_token_segment_id=0,\n","    pad_token_segment_id=0,\n","    cls_token_at_end=False\n",")\n","\n","input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n","input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n","segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n","cls_index = torch.tensor([f.cls_index for f in features], dtype=torch.long)\n","p_mask = torch.tensor([f.p_mask for f in features], dtype=torch.float)\n","\n","example_index = torch.arange(input_ids.size(0), dtype=torch.long)\n","dataset = TensorDataset(input_ids, input_mask, segment_ids, example_index, cls_index, p_mask)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AZGEoDKSrwNm","colab_type":"code","colab":{}},"source":["eval_sampler = SequentialSampler(dataset)\n","eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=8)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EAVGnry4rwNq","colab_type":"code","colab":{}},"source":["def to_list(tensor):\n","    return tensor.detach().cpu().tolist()\n","\n","all_results = []\n","for idx, batch in enumerate(tqdm.tqdm_notebook(eval_dataloader, desc=\"Evaluating\")):\n","    model.eval()\n","    batch = tuple(t.to(device) for t in batch)\n","    with torch.no_grad():\n","        inputs = {'input_ids':      batch[0],\n","                  'attention_mask': batch[1]\n","                  }\n","        inputs['token_type_ids'] = batch[2]\n","        example_indices = batch[3]\n","        outputs = model(**inputs)\n","\n","    for i, example_index in enumerate(example_indices):\n","        eval_feature = features[example_index.item()]\n","        unique_id = int(eval_feature.unique_id)\n","        result = RawResult(unique_id    = unique_id,\n","                           start_logits = to_list(outputs[0][i]),\n","                           end_logits   = to_list(outputs[1][i]))\n","        all_results.append(result)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f48k7ccPrwNv","colab_type":"code","colab":{}},"source":["all_results[0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vDvum4-qrwNz","colab_type":"code","colab":{}},"source":["n_best_size = 5\n","do_lower_case = True\n","output_prediction_file = 'output_1best_file'\n","output_nbest_file = 'output_nbest_file'\n","output_na_prob_file = 'output_na_prob_file'\n","verbose_logging = True\n","version_2_with_negative = True\n","null_score_diff_threshold = 0.0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6W3sVyJerwN2","colab_type":"code","colab":{}},"source":["# Генерируем файл с n лучшими ответами `output_nbest_file`\n","write_predictions(examples, features, all_results, n_best_size,\n","                    max_answer_length, do_lower_case, output_prediction_file,\n","                    output_nbest_file, output_na_prob_file, verbose_logging,\n","                    version_2_with_negative, null_score_diff_threshold)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8UatOAWRrwN5","colab_type":"code","colab":{}},"source":["# Считаем метрики используя официальный SQuAD script\n","evaluate_options = EVAL_OPTS(data_file=PATH_TO_SMALL_DEV_SQUAD,\n","                             pred_file=output_prediction_file,\n","                             na_prob_file=output_na_prob_file)\n","results = evaluate_on_squad(evaluate_options)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oy8bdvqHrwN-","colab_type":"text"},"source":["Посмотрим глазами на вопросы и предсказанные БЕРТом ответы:"]},{"cell_type":"code","metadata":{"id":"9rJCP8BErwN_","colab_type":"code","colab":{}},"source":["with open('output_nbest_file', 'r') as iofile:\n","    predicted_answers = json.load(iofile)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XIwizjxKrwOD","colab_type":"code","colab":{}},"source":["questions = {}\n","for paragraph in small_sample['data'][0]['paragraphs']:\n","    for question in paragraph['qas']:\n","        questions[question['id']] = {\n","            'question': question['question'],\n","            'answers': question['answers'],\n","            'paragraph': paragraph['context']\n","        }"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"bTAcKVBErwOH","colab_type":"code","colab":{}},"source":["for q_num, (key, data) in enumerate(predicted_answers.items()):\n","    gt = '' if len(questions[key]['answers']) == 0 else questions[key]['answers'][0]['text']\n","    print('Вопрос {0}:'.format(q_num+1), questions[key]['question'])\n","    print('-----------------------------------')\n","    print('Ground truth:', gt)\n","    print('-----------------------------------')   \n","    print('Ответы, предсказанные БЕРТом:')\n","    preds = ['{0}) '.format(ans_num + 1) + answer['text'] + \\\n","             ' (уверенность {0:.2f}%)'.format(answer['probability']*100) \\\n","             for ans_num, answer in enumerate(data)]\n","    print('\\n'.join(preds))\n","#     print('-----------------------------------')   \n","#     print('Параграф:', questions[key]['paragraph'])\n","    print('\\n\\n')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EPgho1QMrwOK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":149},"outputId":"e0cc65f2-be1d-4c80-da94-8b3d95fb446b","executionInfo":{"status":"error","timestamp":1587757965164,"user_tz":-240,"elapsed":700,"user":{"displayName":"Alexcei64rus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4SypAswQozU3-DGFu0VQyxwB_TSZLCZKDR1Z6Cg=s64","userId":"06079512506264468138"}}},"source":["!export SQUAD_DIR=/path/to/SQUAD\n","\n","python run_squad.py \\\n","  --model_type bert \\\n","  --model_name_or_path bert-base-cased \\\n","  --do_train \\\n","  --do_eval \\\n","  --do_lower_case \\\n","  --train_file $SQUAD_DIR/train-v1.1.json \\\n","  --predict_file $SQUAD_DIR/dev-v1.1.json \\\n","  --per_gpu_train_batch_size 12 \\\n","  --learning_rate 3e-5 \\\n","  --num_train_epochs 2.0 \\\n","  --max_seq_length 384 \\\n","  --doc_stride 128 \\\n","  --output_dir /tmp/debug_squad/"],"execution_count":4,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-df61e9e4c956>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    python run_squad.py   --model_type bert   --model_name_or_path bert-base-cased   --do_train   --do_eval   --do_lower_case   --train_file $SQUAD_DIR/train-v1.1.json   --predict_file $SQUAD_DIR/dev-v1.1.json   --per_gpu_train_batch_size 12   --learning_rate 3e-5   --num_train_epochs 2.0   --max_seq_length 384   --doc_stride 128   --output_dir /tmp/debug_squad/\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","metadata":{"id":"wccedgGcrwON","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}